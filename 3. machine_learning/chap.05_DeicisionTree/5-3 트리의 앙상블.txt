랜덤포레스트 : 
훈련할 데이터를 랜덤하게 만든다(중복허용) <= 부트스트랩 샘플(bootstrap sample)
부트스트랩 샘플의 크기는 훈련데이터 셋트 크기와 동일.
전체 특성의 제곱근만큼의 특성을 선택(예; 4개의 특성이 있다면 노드마다 2개를 랜덤하게 선택하여 사용)
기본적으로 100개의 결정트리를 훈련.

분류일 경우, 각 트리의 클래스별 확률을 평균하여 가장 높은 확률의 클래스를 예측으로 ..
회귀일 경우, 각 트리의 예측을 평균

랜덤하게 선택한 샘플과 특성을 사용하기 때문에 과대적합 방지, 안정적인 성능

하나의 특성에 과도하게 집중하지 않고, 좀 더 많은 특성이 훈련에 참여할 기회를 얻는다



엑스트라 트리 :
전체 특성중 일부 특성을 랜덤하게 선택하여 노드 분할하는데 사용.
부트스트랩 샘플을 사용하지 않는다.
대신 노드 분할 시, 무작위 분할.
성능은 낮아지지만 과대적합 방지, 검증세트 점수를 높이는 효과.
빠른 계산 속도


그레이던트 부스팅 :
깊이가 얕은 결정 트리를 사용하여 이진 트리 오차를 보완.
기본적으로 깊이가 3인 결정트리를 100개 사용
과대적합에 강하고, 일반적으로 높은 일반화 성능을 기대할 수 있다.

경사하강법을 사용하여 트리를 앙상블에 추가.
분류 : 로지스틱 손실함수
회귀 : 평균제곱 오차함수

결정트리를 계속 추가하면서 가장 낮은 곳을 찾아 이동.
학습율 매개변수로 속도를 조절.

결정트리의 갯수를 늘려도 과대적합에 매우 강하다.
학습률을 증가시키고 트리의 갯수를 늘리면 성능이 조금 더 향상될 수 있다.

일반적으로 랜덤 포레스트보다 조금 더 높은 성능를 얻을 수 있다.
훈련속도가 느리다.



히스토그램 기반 그레이던트 부스팅 :
정형데이터를 다루는 머신러닝 알고리즘 주에 가장 인기가 높다.

입력의 특성을 256개의 구간으로 분리.
따라서 노드를 분할할 때 최적의 분할을 매우 빠르게 찾을 수 있다.

256개의 구간중에서 하나를 떼어 놓고, 누락된 값을 위해 사용.
따러서 누락된 특성이 이어도 전처리가 필요 없다.








