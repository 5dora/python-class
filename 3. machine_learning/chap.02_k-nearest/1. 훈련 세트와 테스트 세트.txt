1. 훈련 세트와 테스트 세트
   
   지도 학습과 비지도학습의 차이.
   모델을 훈련(학습)시키는 훈련 세트
   모델을 평가하기 위한 테스트 세트로 데이터 분리.


지도 학습과 비지도 학습

지도 학습(Supervised Learning)
  훈련을 위한 데이터(입력 : input)와 정답(타겟 : target)이 필요.
  이 둘을 합쳐 훈련 데이터(Training Data)라 칭함.

  입력으로 사용된 길이와 무게를 특성(Feature)하고 호칭.
 
  지도학습은 정답(target)이 있으니 알고리즘이 정답을 맞추는 것을 학습.


비지도 학습(Unsupervised Learning)
  정답(target) 없이 입력 데이터만 사용.
  따라서 무엇인가를 맞추기 보다는데이터를 잘 파악하거나,변형하는데 도움을 준다.


그 외 강화학습(Reinforcement Learning)
  정답(target)이 아니라 알고리즘이 행동한 결과에 따른 보상을 사용하여 학습.
  대표적인 모델인 GAN.



훈련 세트(Train Set)와 테스트 세트(Test Set)
  머신러닝 알고리즘 성능을 제대로 평가하려면
  훈련 데이터와 평가에 사용될 데이터가 각각 달라야 한다.

  방법 : 별도의 데이터를 준비하거나, 준비된 데이터의 일부를 떼어 활용.
          일반적으로 후자를 활용.

  테스트 세트 : 평가에 사용될 데이터 (일반적으로 전체 데이터의 20~30%를 사용)
  훈련 데이터 : 훈련에 사용되는 데이터


훈련 데이터에서 일부를 떼어 내어 테스트 세트로 사용.

1. 도미와 빙어의 데이터를 합쳐 하나의 파이썬 리스트로 준비.
fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 
                31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 
                35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8, 
                10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]
fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 
                500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 
                700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7, 
                7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]

2. 각 생선의 길이와 무게를 한의 리스트로 담은 2차원 리스트 생성
   이 때 하나의 생선 데이터를 샘플(Sample)이라 지칭.
fish_data = [[l, w] for l, w in zip(fish_length, fish_weight)]
fish_target = [1]*35 + [0]*14

   도미와 빙어는 각각 35마리, 14마리. => 전체 데이터는 49개의 샘플.
   사용하는 특성 : 길이와 무게 두가지.
   이 데이터의 처음 35개를 훈련 세트로, 나머지 14개를 테스트 세트로 사용.

2-1. 사이킷런의 KNeighborsClassifier import하고 객체 생성.
from sklearn.neighbors import KNeighborsClassifier
kn = KNeighborsClassifier()

2-2. 데이터 분리 : 슬라이싱을 이용 ([시작 인덱스 : 끝 인덱스])
  훈련 세트로 사용하기 위해 입력값 중 0~34번째 인덱스까지 사용.
train_input = fish_data[:35]

  훈련 세트로 사용하기 위해  타깃값 중 0~34번째 인덱스까지 사용.
train_target = fish_target[:35]

  테스트 세트로 사용하기 위해  입력값 중 35번째부터 마지막 인덱스까지 사용.
test_input = fish_data[35:]

  테스트 세트로 사용하기 위해  타깃값 중 35번째부터 마지막 인덱스까지 사용.
test_target = fish_target[35:]

2-3. 훈련 세트를 fit()메서드로 모델을 훈련하고, 테스트 세트를 score()메서드로 평가.
kn.fit(train_input, train_target)
kn.score(test_input, test_target)

문제 발생 : 정확도가 0.0
원인 파악 : 마지막 14개를 테스트 세트로 떼어 놓았기 때문에, 훈련세트에는 빙어없이 모델이 훈련 됨.
해결 : 훈련 세트와 테스트 세트를 분리시키려면 도미와 빙어가 골고루 섞여야 한다.

샘플링 편향(Sampling Bias)
훈련 세트와 테스트 세트가 골고루 섞이지 않고 샘플링이 한쪽으로 치우쳤다는 의미.


넘파이(numpy)

샘플링 편향을 해결하기 위해 넘파이(numpy)를 사용.
넘파이 : 파이썬의 대표적인 배열(array) 라이브러리
           C언어로 작성되어 속도가 바르다.
           고차원의 배열을 손쉽게 만들고 조작할 수 있는 간편한 도구를 많이 제공.

* 차원(Dimension) : 배열에서의 차원은 좌표계의 축과 유사.
  1차원 배열 : 선 형태
  2차원 배열 : 면 형태
  3차원 배열 : 큐브 형태

  보통의 xy좌표계와 달리 왼쪽아래가 아닌 왼쪽 위부터 시작.

import numpy as np

파이썬 리스트를 넘파이 배열로 변환 : array() 에 파이썬 리스트를 전달
input_arr = np.array(fish_data)
target_arr = np.array(fish_target)
print(input_arr)

배열의 크기 확인 : shape 속성 (샘플(행) 수, 특성(열) 수를 튜플형태로 출력)
print(input_arr.shape)

랜덤하게 샘플을 선택하여(무작위로 샘플고르기) 훈련 세트와 테스트 세트로 분리
주의 : 타깃이 샘플이 함께 이동되어야 한다.

1. 넘파이의 arrange() 함수를 이용하여 0~48까지 1씩 증가하는 인덱스 배열을 생성
index = np.arange(49)

* 넘파이의 seed() : 매번 실행할 때마다 동일한 난수를 생성하기 위한 초기값(정수) 지정.
np.random.seed(42)
   정수는 임의대로 설정 가능

2. random 패키지의 shuffle() 함수를 이용하여 인덱스 배열 데이터를 무작위로 섞기
np.random.shuffle(index)

3. 랜덤하게 섞인 인덱스 배열을 이용하여 전체 데이터를 훈련 세트와 테스트 세트로 나누기
   넘파이의 배열 인덱싱(array indexing)을 이용
      특징 : 여러 개의 인덱스로 한번에 여러 개의 원소(요소, 데이터)를  선택할 수 있다.
train_input = input_arr[index[:35]]
train_target = target_arr[index[:35]]

test_input = input_arr[index[35:]]
test_target = target_arr[index[35:]]

* 2차원 배열은 행과 열 인덱스를 ,로 나누어 지정 
  예) test_input[행,열 : 행, 열]

섞인 데이터 확인을 위한 시각화(산점도:scatter)
import matplotlib.pyplot as plt

plt.scatter(train_input[:, 0], train_input[:, 1])
plt.scatter(test_input[:, 0], test_input[:, 1])
plt.xlabel('length')
plt.ylabel('weight')
plt.show()


두 번째 머신러닝 프로그램

kn.fit(train_input, train_target)
kn.score(test_input, test_target)
kn.predict(test_input)
test_target


